{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifying Uncertainties in Physical Models\n",
    "\n",
    "> Ignorance is preferable to error and he is less remote from the truth who believes nothing than he who believes what is wrong.\n",
    "Thomas Jefferson (1781)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "+ To tell the difference between **aleatory** and **epistemic** uncertainties.\n",
    "+ To define **predictive modeling**.\n",
    "+ To use **probability theory** to represent both aleatory and epistemic uncertainties.\n",
    "+ To **propagate uncertainty** through a physical model using Monte Carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readings\n",
    "\n",
    "+ [Oden, Moser, Ghattas, Computer Predictions with Quantified Uncertainty, Part I](http://www.siam.org/pdf/news/1842.pdf)\n",
    "\n",
    "+ [Oden, Moser, Ghattas, Computer Predictions with Quantified Uncertainty, Part II](http://www.siam.org/pdf/news/1857.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "We are not going to make a big effort to be consistent about the use of the following terms, since their precise meaning is still under debate.\n",
    "\n",
    "### Uncertainty\n",
    "In general, we are uncertain about a logical proposition if we do not know whether it is true or false. \n",
    "In particular, we can be uncertain about:\n",
    "+ the value of a model parameter;\n",
    "+ the mathematical form of a model;\n",
    "+ the initial conditions of a ordinary differntial equations;\n",
    "+ the boundary conditions of a partial differential equation;\n",
    "+ the value of an experimental measurment we are about to perform;\n",
    "+ etc.\n",
    "\n",
    "Uncertainty may be *aleatory* or *epistemic*. Aleatory uncertainty is associated with inherent system randomness. Epistemic uncertainty is associated with lack of knowledge. If you think too hard, the distinction between the two becomes philosophical. We are not going to push this too hard. Fortunately, our approach (the Bayesian approach) treats both uncertainties on an equal footing.\n",
    "\n",
    "### Predictive Modeling\n",
    "*Predictive modeling* is the process of assigning error bars to the predictions of computational models.\n",
    "Ideally, these error bars rigorously quantify the effect of all associated uncertainties.\n",
    "Having quantified and propagated uncertainties through the computational models, one can assess the risk of making decisions based on the model predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Catalytic Conversion of Nitrate to Nitrogen\n",
    "\n",
    "This is Example 3.1 of [(Tsilifis, 2014)](http://arxiv.org/abs/1410.5522).\n",
    "\n",
    "Consider the catalytic\n",
    "conversion of nitrate ($\\mbox{NO}_3^-$) to nitrogen ($\\mbox{N}_2$) and other\n",
    "by-products by electrochemical means.\n",
    "The mechanism that is followed is complex and not well understood.\n",
    "The experiment of [(Katsounaros, 2012)](http://www.sciencedirect.com/science/article/pii/S0013468612005208) confirmed the\n",
    "production of nitrogen ($\\mbox{N}_2$), ammonia\n",
    "($\\mbox{NH}_3$), and nitrous oxide ($\\mbox{N}_2\\mbox{O}$) as final products\n",
    "of the reaction, as well as the intermediate production of nitrite ($\\mbox{NO}_2^-$).\n",
    "The data are reproduced in [Comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values) (CSV) and stored in\n",
    "[data/catalysis.csv](data/catalysis.csv).\n",
    "The time is measured in minutes and the conentrations are measured in $\\mbox{mmol}\\cdot\\mbox{L}^{-1}$.\n",
    "Let's load the data into this notebook using the [Pandas](http://pandas.pydata.org) Python module:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If this fails, you haven't uploaded \"catalysis.csv\".\n",
    "# Repeat 11 of the instructions.\n",
    "import pandas as pd\n",
    "catalysis_data = pd.read_csv('catalysis.csv', index_col=0)\n",
    "catalysis_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the data using [Matplotlib](http://matplotlib.org):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "catalysis_data.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory of catalytic reactions guarantees that the total mass must be conserved.\n",
    "However, this is not the case in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catalysis_data.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This inconsistency suggests the existence of an intermediate unobserved reaction product X.\n",
    "[(Katsounaros, 2012)](http://www.sciencedirect.com/science/article/pii/S0013468612005208) suggested that the following reaction path shown in the following figure.\n",
    "\n",
    "![](scheme.png \"Reaction Scheme\")\n",
    "\n",
    "The dynamical system associated with the reaction is:\n",
    "$$\n",
    "\\begin{array}{cc}\n",
    "\\frac{d \\left[\\mbox{NO}_3^-\\right]}{dt} &= -k_1\\left[\\mbox{NO}_3^-\\right], \\\\\n",
    "\\frac{d\\left[\\mbox{NO}_2^-\\right]}{dt} &= k_1\\left[\\mbox{NO}_3^-\\right] - (k_2 + k_4 +\n",
    "k_5)[\\mbox{NO}_2^-], \\\\\n",
    "\\frac{d \\left[\\mbox{X}\\right]}{dt} &= k_2 \\left[\\mbox{NO}_2^-\\right] - k_3 [X],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2\\right]}{dt} &= k_3 \\left[\\mbox{X}\\right], \\\\\n",
    "\\frac{d \\left[\\mbox{NH}_3\\right]}{dt} &= k_4 \\left[\\mbox{NO}_2^-\\right],\\\\\n",
    "\\frac{d \\left[\\mbox{N}_2O\\right]}{dt} &= k_5 \\left[\\mbox{NO}_2^-\\right],\n",
    "\\end{array}\n",
    "$$\n",
    "where $[\\cdot]$ denotes the concentration of a quantity, and\n",
    "$k_i > 0$, $i=1,...5$ are the *kinetic rate constants*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 01\n",
    "\n",
    "<span><a class=\"pd-embed\" id=\"pd1514456211022\" href=\"http://ebilionis.polldaddy.com/s/handout-01-01\">Click here to respond</a></span>\n",
    "<script type=\"text/javascript\">\n",
    "var _polldaddy = [] || _polldaddy;\n",
    "\n",
    "_polldaddy.push( {\n",
    "    type: 'button',\n",
    "    title: 'Take Our Survey!',\n",
    "    style: 'inline',\n",
    "    domain: 'ebilionis.polldaddy.com/s/',\n",
    "    id: 'handout-01-01',\n",
    "    placeholder: 'pd1514456211022'\n",
    "} );\n",
    "\n",
    "(function(d,c,j){if(!document.getElementById(j)){var pd=d.createElement(c),s;pd.id=j;pd.src=('https:'==document.location.protocol)?'https://polldaddy.com/survey.js':'http://i0.poll.fm/survey.js';s=document.getElementsByTagName(c)[0];s.parentNode.insertBefore(pd,s);}}(document,'script','pd-embed'));\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computational Model\n",
    "\n",
    "We will develop a generic computational model for the solution of dynamical systems and we will use it to study the catalysis problem. The code relies on the [Fourth-order Runge-Kutta method](https://en.wikipedia.org/wiki/Rungeâ€“Kutta_methods) and is a modified copy of [http://www.math-cs.gordon.edu/courses/ma342/python/diffeq.py](http://www.math-cs.gordon.edu/courses/ma342/python/diffeq.py) developed by Jonathan Senning. The code solves:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\dot{\\mathbf{y}} &=& f(\\mathbf{y}, t),\\\\\n",
    "\\mathbf{y}(0) &=& \\mathbf{y}_0.\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def rk45( f, y0, t, args=() ):\n",
    "    \"\"\"Fourth-order Runge-Kutta method with error estimate.\n",
    "\n",
    "    USAGE:\n",
    "        y = rk45(f, x0, t, args=())\n",
    "\n",
    "    INPUT:\n",
    "        f     - function of x and t equal to dx/dt.  x may be multivalued,\n",
    "                in which case it should a list or a NumPy array.  In this\n",
    "                case f must return a NumPy array with the same dimension\n",
    "                as x.\n",
    "        y0    - the initial condition(s).  Specifies the value of x when\n",
    "                t = t[0].  Can be either a scalar or a list or NumPy array\n",
    "                if a system of equations is being solved.\n",
    "        t     - list or NumPy array of t values to compute solution at.\n",
    "                t[0] is the the initial condition point, and the difference\n",
    "                h=t[i+1]-t[i] determines the step size h.\n",
    "        args  - any other parameters of the function f.\n",
    "\n",
    "    OUTPUT:\n",
    "        y     - NumPy array containing solution values corresponding to each\n",
    "                entry in t array.  If a system is being solved, x will be\n",
    "                an array of arrays.\n",
    "\n",
    "    NOTES:\n",
    "        This version is based on the algorithm presented in \"Numerical\n",
    "        Mathematics and Computing\" 6th Edition, by Cheney and Kincaid,\n",
    "        Brooks-Cole, 2008.\n",
    "    \"\"\"\n",
    "\n",
    "    # Coefficients used to compute the independent variable argument of f\n",
    "\n",
    "    c20  =   2.500000000000000e-01  #  1/4\n",
    "    c30  =   3.750000000000000e-01  #  3/8\n",
    "    c40  =   9.230769230769231e-01  #  12/13\n",
    "    c50  =   1.000000000000000e+00  #  1\n",
    "    c60  =   5.000000000000000e-01  #  1/2\n",
    "\n",
    "    # Coefficients used to compute the dependent variable argument of f\n",
    "\n",
    "    c21 =   2.500000000000000e-01  #  1/4\n",
    "    c31 =   9.375000000000000e-02  #  3/32\n",
    "    c32 =   2.812500000000000e-01  #  9/32\n",
    "    c41 =   8.793809740555303e-01  #  1932/2197\n",
    "    c42 =  -3.277196176604461e+00  # -7200/2197\n",
    "    c43 =   3.320892125625853e+00  #  7296/2197\n",
    "    c51 =   2.032407407407407e+00  #  439/216\n",
    "    c52 =  -8.000000000000000e+00  # -8\n",
    "    c53 =   7.173489278752436e+00  #  3680/513\n",
    "    c54 =  -2.058966861598441e-01  # -845/4104\n",
    "    c61 =  -2.962962962962963e-01  # -8/27\n",
    "    c62 =   2.000000000000000e+00  #  2\n",
    "    c63 =  -1.381676413255361e+00  # -3544/2565\n",
    "    c64 =   4.529727095516569e-01  #  1859/4104\n",
    "    c65 =  -2.750000000000000e-01  # -11/40\n",
    "\n",
    "    # Coefficients used to compute 4th order RK estimate\n",
    "\n",
    "    a1  =   1.157407407407407e-01  #  25/216\n",
    "    a2  =   0.000000000000000e-00  #  0\n",
    "    a3  =   5.489278752436647e-01  #  1408/2565\n",
    "    a4  =   5.353313840155945e-01  #  2197/4104\n",
    "    a5  =  -2.000000000000000e-01  # -1/5\n",
    "\n",
    "    b1  =   1.185185185185185e-01  #  16.0/135.0\n",
    "    b2  =   0.000000000000000e-00  #  0\n",
    "    b3  =   5.189863547758284e-01  #  6656.0/12825.0\n",
    "    b4  =   5.061314903420167e-01  #  28561.0/56430.0\n",
    "    b5  =  -1.800000000000000e-01  # -9.0/50.0\n",
    "    b6  =   3.636363636363636e-02  #  2.0/55.0\n",
    "\n",
    "    n = len( t )\n",
    "    y = np.array( [ y0 ] * n )\n",
    "    for i in xrange( n - 1 ):\n",
    "        h = t[i+1] - t[i]\n",
    "        k1 = h * f( y[i], t[i], *args )\n",
    "        k2 = h * f( y[i] + c21 * k1, t[i] + c20 * h, *args )\n",
    "        k3 = h * f( y[i] + c31 * k1 + c32 * k2, t[i] + c30 * h, *args )\n",
    "        k4 = h * f( y[i] + c41 * k1 + c42 * k2 + c43 * k3, t[i] + c40 * h, *args )\n",
    "        k5 = h * f( y[i] + c51 * k1 + c52 * k2 + c53 * k3 + c54 * k4, \\\n",
    "                        t[i] + h, *args )\n",
    "        k6 = h * f( \\\n",
    "            y[i] + c61 * k1 + c62 * k2 + c63 * k3 + c64 * k4 + c65 * k5, \\\n",
    "            t[i] + c60 * h, *args )\n",
    "\n",
    "        y[i+1] = y[i] + a1 * k1 + a3 * k3 + a4 * k4 + a5 * k5\n",
    "        y5 = y[i] + b1 * k1 + b3 * k3 + b4 * k4 + b5 * k5 + b6 * k6\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calibrating the Catalysis Model to the Experimental Data\n",
    "\n",
    "Now that we are certain that our generic ODE solver works, let us use it to develop a solver for the catalysis model. All, we need to do is define the right hand side of the dynamics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_catalysis(y, t, kappa):\n",
    "    rhs = np.zeros((6,))\n",
    "    rhs[0] = -kappa[0] * y[0]\n",
    "    rhs[1] = kappa[0] * y[0] - (kappa[1] + kappa[3] + kappa[4]) * y[1]\n",
    "    rhs[2] = kappa[1] * y[1] - kappa[2] * y[2]\n",
    "    rhs[3] = kappa[2] * y[2]\n",
    "    rhs[4] = kappa[3] * y[1]\n",
    "    rhs[5] = kappa[4] * y[1]\n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to calibrate the parameters of the model to the data, manually. Because the parameters are too small, let us work with the transformed version:\n",
    "\n",
    "$$\n",
    "\\xi_i = \\log\\left(\\frac{k_i}{180}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive\n",
    "def compare_model_to_data(xi1 = 1.359, xi2 = 1.657, xi3 = 1.347, xi4 = -.162, xi5 = -1.009):\n",
    "    \"\"\"\n",
    "    Compare the model predictions to the data.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, 180, 100)\n",
    "    kappa = np.exp([xi1, xi2, xi3, xi4, xi5]) / 180.\n",
    "    y = rk45(f_catalysis, (500., 0., 0., 0., 0., 0.), t, args=(kappa,))\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    catalysis_data.plot(ax=ax, style='s')\n",
    "    ax.plot(t, y[:, 0], color=sns.color_palette()[0], label='Model NO3-')\n",
    "    ax.plot(t, y[:, 1], color=sns.color_palette()[1], label='Model NO2-')\n",
    "    ax.plot(t, y[:, 2], color=sns.color_palette()[5], label='Model X')\n",
    "    ax.plot(t, y[:, 3], color=sns.color_palette()[2], label='Model N2')\n",
    "    ax.plot(t, y[:, 4], color=sns.color_palette()[3], label='Model NH3')\n",
    "    ax.plot(t, y[:, 5], color=sns.color_palette()[4], label='Model N2O')\n",
    "    plt.legend()\n",
    "    \n",
    "interactive(compare_model_to_data, xi1 = (-2, 2, 0.05), xi2 = (-2, 2, 0.05), xi3 = (-2, 2, 0.05),\n",
    "                                   xi4 = (-2, 2, 0.05), xi5 = (-2, 2, 0.05) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the calibration problem. \n",
    "\n",
    "### Questions 02\n",
    "\n",
    "<span><a class=\"pd-embed\" id=\"pd1514457269730\" href=\"http://ebilionis.polldaddy.com/s/handout-01-02\">Click to respond.</a></span>\n",
    "<script type=\"text/javascript\">\n",
    "var _polldaddy = [] || _polldaddy;\n",
    "\n",
    "_polldaddy.push( {\n",
    "    type: 'button',\n",
    "    title: 'Click to respond.',\n",
    "    style: 'inline',\n",
    "    domain: 'ebilionis.polldaddy.com/s/',\n",
    "    id: 'handout-01-02',\n",
    "    placeholder: 'pd1514457269730'\n",
    "} );\n",
    "\n",
    "(function(d,c,j){if(!document.getElementById(j)){var pd=d.createElement(c),s;pd.id=j;pd.src=('https:'==document.location.protocol)?'https://polldaddy.com/survey.js':'http://i0.poll.fm/survey.js';s=document.getElementsByTagName(c)[0];s.parentNode.insertBefore(pd,s);}}(document,'script','pd-embed'));\n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty Propagation\n",
    "\n",
    "As discussed in Question 2 above, there various reasons why a model cannot be calibrated perfectly. Some of these are:\n",
    "\n",
    "+ lack of data;\n",
    "+ the existence of measurement noise;\n",
    "+ the fact that the model is just not perfect.\n",
    "\n",
    "Ignoring for the moment the possibility that the model is just bluntly wrong, we see that the lack of data or the presence of noise will induce some uncertainty in the values of the calibrated parameters. We are going to represent uncertainty on parameters by assigning a probability density on them. There are systematic ways of estimating the uncertainty induced because of the calibration process, but this will not concern us now.\n",
    "For the moment, assume that somebody told us that the uncertainty in the scaled parameters $\\xi_i$ of the model is as follows:\n",
    "\n",
    "\n",
    "| Variable | Value |\n",
    "|---------|------------------|\n",
    "| $\\xi_1$ |$1.35\\pm 0.05$ |\n",
    "| $\\xi_2$ |$1.65\\pm 0.08$   |\n",
    "| $\\xi_3$ |$1.34\\pm 0.11$ |\n",
    "| $\\xi_4$ |$-0.16\\pm 0.16$ |\n",
    "| $\\xi_5$ |$-3.84\\pm 0.20$ |\n",
    "\n",
    "But what does this information actually mean? As we will discuss in the following lectures, this information can be used to assign a probability density on each one of these parameters, say $p(\\xi_i)$, that *models* our state of knowledge about them. For example, let us assume that our state of knowledge about $\\xi_1$ is given by a Gaussian probability density:\n",
    "\n",
    "$$\n",
    "p(\\xi_1) = \\mathcal{N}(\\xi_1|\\mu_1=1.35, \\sigma^2 = 0.05^2),\n",
    "$$\n",
    "\n",
    "which we can visualize as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "xi1 = np.linspace(-0, 2, 200)\n",
    "plt.plot(xi1, norm.pdf(xi1, loc=1.35, scale=0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we do not beleive that the value of the parameter can be less than 1.0 or greater than 1.6. Note that, we are deliberately trying to avoid the use of the term \"random\". There is nothing random in our example. Probability models a state of knowledge.\n",
    "\n",
    "How does this uncertainty propagate through the model? We will study this question with a simple numerical experiment. We are going to assign Gaussian probability densities on all the $\\xi_i$'s, sample them a few times, and run our catalysis model for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_samples(mu1 = 1.359, sig1=0.055,\n",
    "                mu2 = 1.657, sig2=0.086,\n",
    "                mu3 = 1.347, sig3=0.118,\n",
    "                mu4 = -.162, sig4=0.167,\n",
    "                mu5 = -1.009, sig5=0.368,\n",
    "                num_samples=1):\n",
    "    \"\"\"\n",
    "    Take a few samples of the model to study uncertainty propagation.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    catalysis_data.plot(ax=ax, style='s')\n",
    "    t = np.linspace(0, 180, 100)\n",
    "    for i in xrange(num_samples):\n",
    "        xi1 = norm.rvs(loc=mu1, scale=sig1)\n",
    "        xi2 = norm.rvs(loc=mu2, scale=sig2)\n",
    "        xi3 = norm.rvs(loc=mu3, scale=sig3)\n",
    "        xi4 = norm.rvs(loc=mu4, scale=sig4)\n",
    "        xi5 = norm.rvs(loc=mu5, scale=sig5)\n",
    "        kappa = np.exp([xi1, xi2, xi3, xi4, xi5]) / 180.\n",
    "        y = rk45(f_catalysis, (500., 0., 0., 0., 0., 0.), t, args=(kappa,))\n",
    "        ax.plot(t, y[:, 0], linewidth=0.5, color=sns.color_palette()[0])#, label='Model NO3-')\n",
    "        ax.plot(t, y[:, 1], linewidth=0.5, color=sns.color_palette()[1])#, label='Model NO2-')\n",
    "        ax.plot(t, y[:, 2], linewidth=0.5, color=sns.color_palette()[5])#, label='Model X')\n",
    "        ax.plot(t, y[:, 3], linewidth=0.5, color=sns.color_palette()[2])#, label='Model N2')\n",
    "        ax.plot(t, y[:, 4], linewidth=0.5, color=sns.color_palette()[3])#, label='Model NH3')\n",
    "        ax.plot(t, y[:, 5], linewidth=0.5, color=sns.color_palette()[4])#, label='Model N2O')\n",
    "    plt.legend()\n",
    "\n",
    "interactive(plot_samples, mu1 = (-2, 2, 0.05), sig1=(0.02, 0.4, 0.01),\n",
    "                                   mu2 = (-2, 2, 0.05), sig2=(0.02, 0.4, 0.01),\n",
    "                                   mu3 = (-2, 2, 0.05), sig3=(0.02, 0.4, 0.01),\n",
    "                                   mu4 = (-2, 2, 0.05), sig4=(0.02, 0.4, 0.01),\n",
    "                                   mu5 = (-2, 2, 0.05), sig5=(0.02, 0.4, 0.01),\n",
    "            num_samples=(1, 1100, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 03\n",
    "\n",
    "Increase the number of samples from 1, to 10, to 100, to 1000. Each time you get a better description of uncertainty. This is a Monte Carlo simulation. Then, take the survey.\n",
    "\n",
    "\n",
    "<span><a class=\"pd-embed\" id=\"pd1514457576895\" href=\"http://ebilionis.polldaddy.com/s/handout-01-03\">Click here to respond.</a></span>\n",
    "<script type=\"text/javascript\">\n",
    "var _polldaddy = [] || _polldaddy;\n",
    "\n",
    "_polldaddy.push( {\n",
    "    type: 'button',\n",
    "    title: 'Click here to respond.',\n",
    "    style: 'inline',\n",
    "    domain: 'ebilionis.polldaddy.com/s/',\n",
    "    id: 'handout-01-03',\n",
    "    placeholder: 'pd1514457576895'\n",
    "} );\n",
    "\n",
    "(function(d,c,j){if(!document.getElementById(j)){var pd=d.createElement(c),s;pd.id=j;pd.src=('https:'==document.location.protocol)?'https://polldaddy.com/survey.js':'http://i0.poll.fm/survey.js';s=document.getElementsByTagName(c)[0];s.parentNode.insertBefore(pd,s);}}(document,'script','pd-embed'));\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "number",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
